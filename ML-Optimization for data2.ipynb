{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IDfg</th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>...</th>\n",
       "      <th>WAR</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LD%</th>\n",
       "      <th>GB%</th>\n",
       "      <th>Contact%</th>\n",
       "      <th>SwStr%</th>\n",
       "      <th>Barrel%</th>\n",
       "      <th>EV</th>\n",
       "      <th>maxEV</th>\n",
       "      <th>next_year_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15640</td>\n",
       "      <td>2022</td>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>30</td>\n",
       "      <td>696</td>\n",
       "      <td>177</td>\n",
       "      <td>62</td>\n",
       "      <td>133</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.262</td>\n",
       "      <td>95.8</td>\n",
       "      <td>118.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13611</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>25</td>\n",
       "      <td>614</td>\n",
       "      <td>180</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.131</td>\n",
       "      <td>92.3</td>\n",
       "      <td>110.6</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10155</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mike Trout</td>\n",
       "      <td>26</td>\n",
       "      <td>608</td>\n",
       "      <td>147</td>\n",
       "      <td>39</td>\n",
       "      <td>101</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.153</td>\n",
       "      <td>91.2</td>\n",
       "      <td>118.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11579</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bryce Harper</td>\n",
       "      <td>22</td>\n",
       "      <td>654</td>\n",
       "      <td>172</td>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.122</td>\n",
       "      <td>91.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10155</td>\n",
       "      <td>2015</td>\n",
       "      <td>Mike Trout</td>\n",
       "      <td>23</td>\n",
       "      <td>682</td>\n",
       "      <td>172</td>\n",
       "      <td>41</td>\n",
       "      <td>104</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.161</td>\n",
       "      <td>92.9</td>\n",
       "      <td>117.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   IDfg  Season          Name  Age   PA    H  HR    R  RBI  ...  \\\n",
       "0           0  15640    2022   Aaron Judge   30  696  177  62  133  131  ...   \n",
       "1           1  13611    2018  Mookie Betts   25  614  180  32  129   80  ...   \n",
       "2           2  10155    2018    Mike Trout   26  608  147  39  101   79  ...   \n",
       "3           3  11579    2015  Bryce Harper   22  654  172  42  118   99  ...   \n",
       "4           4  10155    2015    Mike Trout   23  682  172  41  104   90  ...   \n",
       "\n",
       "    WAR  BABIP    LD%    GB%  Contact%  SwStr%  Barrel%    EV  maxEV  \\\n",
       "0  11.6  0.340  0.193  0.373     0.722   0.118    0.262  95.8  118.4   \n",
       "1  10.4  0.368  0.212  0.339     0.859   0.050    0.131  92.3  110.6   \n",
       "2   9.5  0.346  0.234  0.313     0.841   0.060    0.153  91.2  118.0   \n",
       "3   9.3  0.369  0.222  0.385     0.754   0.108    0.122  91.4  116.0   \n",
       "4   9.3  0.344  0.244  0.372     0.800   0.075    0.161  92.9  117.7   \n",
       "\n",
       "   next_year_hits  \n",
       "0             NaN  \n",
       "1           176.0  \n",
       "2           137.0  \n",
       "3           123.0  \n",
       "4           173.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('resources/data2.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4827 entries, 0 to 4826\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      4827 non-null   int64  \n",
      " 1   IDfg            4827 non-null   int64  \n",
      " 2   Season          4827 non-null   int64  \n",
      " 3   Name            4827 non-null   object \n",
      " 4   Age             4827 non-null   int64  \n",
      " 5   PA              4827 non-null   int64  \n",
      " 6   H               4827 non-null   int64  \n",
      " 7   HR              4827 non-null   int64  \n",
      " 8   R               4827 non-null   int64  \n",
      " 9   RBI             4827 non-null   int64  \n",
      " 10  SB              4827 non-null   int64  \n",
      " 11  BB              4827 non-null   int64  \n",
      " 12  SO              4827 non-null   int64  \n",
      " 13  AVG             4827 non-null   float64\n",
      " 14  OBP             4827 non-null   float64\n",
      " 15  SLG             4827 non-null   float64\n",
      " 16  OPS             4827 non-null   float64\n",
      " 17  wOBA            4827 non-null   float64\n",
      " 18  WAR             4827 non-null   float64\n",
      " 19  BABIP           4827 non-null   float64\n",
      " 20  LD%             4827 non-null   float64\n",
      " 21  GB%             4827 non-null   float64\n",
      " 22  Contact%        4827 non-null   float64\n",
      " 23  SwStr%          4827 non-null   float64\n",
      " 24  Barrel%         4268 non-null   float64\n",
      " 25  EV              4268 non-null   float64\n",
      " 26  maxEV           4268 non-null   float64\n",
      " 27  next_year_hits  3224 non-null   float64\n",
      "dtypes: float64(15), int64(12), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IDfg</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>...</th>\n",
       "      <th>WAR</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LD%</th>\n",
       "      <th>GB%</th>\n",
       "      <th>Contact%</th>\n",
       "      <th>SwStr%</th>\n",
       "      <th>Barrel%</th>\n",
       "      <th>EV</th>\n",
       "      <th>maxEV</th>\n",
       "      <th>next_year_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4827.000000</td>\n",
       "      <td>4268.000000</td>\n",
       "      <td>4268.000000</td>\n",
       "      <td>4268.000000</td>\n",
       "      <td>3224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2413.000000</td>\n",
       "      <td>10908.943443</td>\n",
       "      <td>2017.947586</td>\n",
       "      <td>28.074788</td>\n",
       "      <td>309.751191</td>\n",
       "      <td>70.164491</td>\n",
       "      <td>9.562875</td>\n",
       "      <td>36.810234</td>\n",
       "      <td>35.211933</td>\n",
       "      <td>4.207790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016532</td>\n",
       "      <td>0.288582</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.447767</td>\n",
       "      <td>0.764373</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.060434</td>\n",
       "      <td>87.877530</td>\n",
       "      <td>109.200351</td>\n",
       "      <td>79.958437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1393.579205</td>\n",
       "      <td>5612.115006</td>\n",
       "      <td>2.596570</td>\n",
       "      <td>3.803885</td>\n",
       "      <td>201.281248</td>\n",
       "      <td>51.270912</td>\n",
       "      <td>9.620564</td>\n",
       "      <td>28.311468</td>\n",
       "      <td>28.307244</td>\n",
       "      <td>6.839656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.690569</td>\n",
       "      <td>0.053701</td>\n",
       "      <td>0.044311</td>\n",
       "      <td>0.090762</td>\n",
       "      <td>0.070046</td>\n",
       "      <td>0.037340</td>\n",
       "      <td>0.042994</td>\n",
       "      <td>2.699814</td>\n",
       "      <td>3.791055</td>\n",
       "      <td>51.448755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.400000</td>\n",
       "      <td>90.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1206.500000</td>\n",
       "      <td>5942.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2413.000000</td>\n",
       "      <td>11204.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>88.100000</td>\n",
       "      <td>109.300000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3619.500000</td>\n",
       "      <td>14916.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>89.700000</td>\n",
       "      <td>111.700000</td>\n",
       "      <td>121.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4826.000000</td>\n",
       "      <td>30116.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0          IDfg       Season          Age           PA  \\\n",
       "count  4827.000000   4827.000000  4827.000000  4827.000000  4827.000000   \n",
       "mean   2413.000000  10908.943443  2017.947586    28.074788   309.751191   \n",
       "std    1393.579205   5612.115006     2.596570     3.803885   201.281248   \n",
       "min       0.000000     25.000000  2014.000000    19.000000    50.000000   \n",
       "25%    1206.500000   5942.000000  2016.000000    25.000000   127.000000   \n",
       "50%    2413.000000  11204.000000  2018.000000    28.000000   263.000000   \n",
       "75%    3619.500000  14916.000000  2020.000000    31.000000   483.000000   \n",
       "max    4826.000000  30116.000000  2022.000000    43.000000   747.000000   \n",
       "\n",
       "                 H           HR            R          RBI           SB  ...  \\\n",
       "count  4827.000000  4827.000000  4827.000000  4827.000000  4827.000000  ...   \n",
       "mean     70.164491     9.562875    36.810234    35.211933     4.207790  ...   \n",
       "std      51.270912     9.620564    28.311468    28.307244     6.839656  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%      25.000000     2.000000    13.000000    11.000000     0.000000  ...   \n",
       "50%      56.000000     6.000000    30.000000    28.000000     2.000000  ...   \n",
       "75%     111.000000    14.000000    56.000000    53.000000     5.000000  ...   \n",
       "max     225.000000    62.000000   137.000000   133.000000    64.000000  ...   \n",
       "\n",
       "               WAR        BABIP          LD%          GB%     Contact%  \\\n",
       "count  4827.000000  4827.000000  4827.000000  4827.000000  4827.000000   \n",
       "mean      1.016532     0.288582     0.204869     0.447767     0.764373   \n",
       "std       1.690569     0.053701     0.044311     0.090762     0.070046   \n",
       "min      -2.600000     0.000000     0.000000     0.167000     0.375000   \n",
       "25%      -0.100000     0.260000     0.179000     0.388000     0.722000   \n",
       "50%       0.500000     0.293000     0.206000     0.439000     0.769000   \n",
       "75%       1.800000     0.323000     0.231000     0.494500     0.813000   \n",
       "max      11.600000     0.548000     0.412000     0.958000     0.951000   \n",
       "\n",
       "            SwStr%      Barrel%           EV        maxEV  next_year_hits  \n",
       "count  4827.000000  4268.000000  4268.000000  4268.000000     3224.000000  \n",
       "mean      0.111504     0.060434    87.877530   109.200351       79.958437  \n",
       "std       0.037340     0.042994     2.699814     3.791055       51.448755  \n",
       "min       0.019000     0.000000    72.400000    90.600000        1.000000  \n",
       "25%       0.085000     0.028000    86.300000   107.000000       35.000000  \n",
       "50%       0.109000     0.054000    88.100000   109.300000       73.000000  \n",
       "75%       0.134000     0.087000    89.700000   111.700000      121.250000  \n",
       "max       0.300000     0.316000    96.500000   122.400000      216.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4827, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDfg\n",
       "7859     9\n",
       "1744     9\n",
       "2396     9\n",
       "13611    9\n",
       "10847    9\n",
       "        ..\n",
       "19361    1\n",
       "8137     1\n",
       "12768    1\n",
       "14682    1\n",
       "11376    1\n",
       "Name: count, Length: 1380, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how do I get the value counts for the IDfg\n",
    "data2['IDfg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where the IDfg only appears 3 or more times\n",
    "data2 = data2[data2.groupby('IDfg')['IDfg'].transform('count') > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDfg\n",
       "8709     9\n",
       "6012     9\n",
       "13757    9\n",
       "5760     9\n",
       "8202     9\n",
       "        ..\n",
       "5305     3\n",
       "7620     3\n",
       "12547    3\n",
       "16885    3\n",
       "7399     3\n",
       "Name: count, Length: 743, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['IDfg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/karliebaxter/Project-2/ML-Optimization for data2.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#run a random forest classifier on the data to predict the next year's 'H' column for each 'IDfg'\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#drop 'Name' column\n",
    "data2 = data2.drop('Name', axis=1)\n",
    "\n",
    "#drop rows with missing values\n",
    "data2 = data2.dropna()\n",
    "\n",
    "X = data2.drop(['IDfg', 'H'], axis=1)\n",
    "y = data2['H']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/karliebaxter/Project-2/ML-Optimization for data2.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karliebaxter/Project-2/ML-Optimization%20for%20data2.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1205\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1207\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1208\u001b[0m     X,\n\u001b[1;32m   1209\u001b[0m     y,\n\u001b[1;32m   1210\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     dtype\u001b[39m=\u001b[39m_dtype,\n\u001b[1;32m   1212\u001b[0m     order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39msolver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1214\u001b[0m )\n\u001b[1;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[39m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "#run a logistic regression on the data to predict the next year's 'H' column for each 'IDfg'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

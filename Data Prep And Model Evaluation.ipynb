{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from pybaseball import batting_stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (batting_stats(2014, 2018))\n",
    "X = data[['Age', 'GB', 'LD', 'SwStr%']]\n",
    "y = data['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=128, random_state=78,)\n",
    "\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.944221213469784\n",
      "Testing Score: 0.5011051973595293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training Score: {rf_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {rf_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = 'resources\\cleaned_extended_data3 (2).csv' \n",
    "df = pd.read_csv(data_path)\n",
    "X = df.drop('next_year_hits', axis=1)  \n",
    "y = df['next_year_hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=190, learning_rate=0.1, max_depth=8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 398.34215931956476\n",
      "MAE: 13.657809975591451\n",
      "R² Score: 0.8506441710830508\n",
      "Train score: 0.9894306570044707\n",
      "Test score: 0.8506441710830508\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R² Score: {r2}')\n",
    "# show train score\n",
    "print(f'Train score: {gb_model.score(X_train, y_train)}')\n",
    "# show test score\n",
    "print(f'Test score: {gb_model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wizard's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    reg = model.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = reg.score(X_train, y_train)\n",
    "    test_score = reg.score(X_test, y_test)\n",
    "    \n",
    "    # print(f'Model: {type(reg).__name__}')\n",
    "    \n",
    "    # print(f'Train score: {train_score}')\n",
    "    # print(f'Test Score: {test_score}\\n')    \n",
    "    \n",
    "    return {'train':train_score, 'test':test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('resources\\data2.csv')\n",
    "relevant_cols=['Age','PA','H','HR','R','RBI','SB','BB','SO','AVG','OBP','SLG','OPS','wOBA','WAR','next_year_hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>WAR</th>\n",
       "      <th>next_year_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>614</td>\n",
       "      <td>180</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.449</td>\n",
       "      <td>10.4</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>608</td>\n",
       "      <td>147</td>\n",
       "      <td>39</td>\n",
       "      <td>101</td>\n",
       "      <td>79</td>\n",
       "      <td>24</td>\n",
       "      <td>122</td>\n",
       "      <td>124</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.628</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.447</td>\n",
       "      <td>9.5</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>654</td>\n",
       "      <td>172</td>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>131</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.461</td>\n",
       "      <td>9.3</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>682</td>\n",
       "      <td>172</td>\n",
       "      <td>41</td>\n",
       "      <td>104</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>92</td>\n",
       "      <td>158</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.415</td>\n",
       "      <td>9.3</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>678</td>\n",
       "      <td>154</td>\n",
       "      <td>52</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>208</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.430</td>\n",
       "      <td>8.7</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   PA    H  HR    R  RBI  SB   BB   SO    AVG    OBP    SLG    OPS  \\\n",
       "0   25  614  180  32  129   80  30   81   91  0.346  0.438  0.640  1.078   \n",
       "1   26  608  147  39  101   79  24  122  124  0.312  0.460  0.628  1.088   \n",
       "2   22  654  172  42  118   99   6  124  131  0.330  0.460  0.649  1.109   \n",
       "3   23  682  172  41  104   90  11   92  158  0.299  0.402  0.590  0.991   \n",
       "4   25  678  154  52  128  114   9  127  208  0.284  0.422  0.627  1.049   \n",
       "\n",
       "    wOBA   WAR  next_year_hits  \n",
       "0  0.449  10.4           176.0  \n",
       "1  0.447   9.5           137.0  \n",
       "2  0.461   9.3           123.0  \n",
       "3  0.415   9.3           173.0  \n",
       "4  0.430   8.7           115.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data2.copy(deep=True)\n",
    "\n",
    "relevant = df.loc[:,relevant_cols]\n",
    "relevant = relevant.dropna()\n",
    "\n",
    "relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>614</td>\n",
       "      <td>180</td>\n",
       "      <td>32</td>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.449</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>608</td>\n",
       "      <td>147</td>\n",
       "      <td>39</td>\n",
       "      <td>101</td>\n",
       "      <td>79</td>\n",
       "      <td>24</td>\n",
       "      <td>122</td>\n",
       "      <td>124</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.628</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.447</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>654</td>\n",
       "      <td>172</td>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>131</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.461</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>682</td>\n",
       "      <td>172</td>\n",
       "      <td>41</td>\n",
       "      <td>104</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>92</td>\n",
       "      <td>158</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.415</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>678</td>\n",
       "      <td>154</td>\n",
       "      <td>52</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>208</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.430</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   PA    H  HR    R  RBI  SB   BB   SO    AVG    OBP    SLG    OPS  \\\n",
       "0   25  614  180  32  129   80  30   81   91  0.346  0.438  0.640  1.078   \n",
       "1   26  608  147  39  101   79  24  122  124  0.312  0.460  0.628  1.088   \n",
       "2   22  654  172  42  118   99   6  124  131  0.330  0.460  0.649  1.109   \n",
       "3   23  682  172  41  104   90  11   92  158  0.299  0.402  0.590  0.991   \n",
       "4   25  678  154  52  128  114   9  127  208  0.284  0.422  0.627  1.049   \n",
       "\n",
       "    wOBA   WAR  \n",
       "0  0.449  10.4  \n",
       "1  0.447   9.5  \n",
       "2  0.461   9.3  \n",
       "3  0.415   9.3  \n",
       "4  0.430   8.7  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = relevant.pop('next_year_hits')\n",
    "X = relevant\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, X, y, model_name):\n",
    "    \n",
    "    results = []\n",
    "    max_r2 = -999.0\n",
    "    max_index = -999\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for trees in range(40, 200, 10):\n",
    "        for depth in range(2, 10, 2):\n",
    "            \n",
    "            print(f'\\ntrees: {trees}, max-depth: {depth}')\n",
    "        \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "            scaler = StandardScaler().fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            forest_data = [X_train, X_test, y_train, y_test] \n",
    "        \n",
    "            scores = test_model(model(n_estimators=trees, max_depth=depth), forest_data)\n",
    "        \n",
    "            results.append((trees, depth, scores['train'], scores['test'], len(X)))\n",
    "        \n",
    "            if scores['test']>max_r2:\n",
    "                max_r2 = scores['test']\n",
    "                max_index=idx\n",
    "                print(f'New max score: {max_r2}')\n",
    "                \n",
    "            idx += 1\n",
    "            \n",
    "    best = results[max_index]\n",
    "    print(f'\\n\\nbest {model_name}\\ntrain score: {best[2]}\\ntest score: {best[3]}\\nnum rows: {best[4]}\\ntrees: {best[0]}\\nmax-depth: {best[1]}\\n\\n')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trees: 40, max-depth: 2\n",
      "New max score: 0.30306105796070837\n",
      "\n",
      "trees: 40, max-depth: 4\n",
      "New max score: 0.38958277912228245\n",
      "\n",
      "trees: 40, max-depth: 6\n",
      "New max score: 0.4633674279301355\n",
      "\n",
      "trees: 40, max-depth: 8\n",
      "New max score: 0.540624890160579\n",
      "\n",
      "trees: 50, max-depth: 2\n",
      "\n",
      "trees: 50, max-depth: 4\n",
      "\n",
      "trees: 50, max-depth: 6\n",
      "\n",
      "trees: 50, max-depth: 8\n",
      "New max score: 0.5413284055070626\n",
      "\n",
      "trees: 60, max-depth: 2\n",
      "\n",
      "trees: 60, max-depth: 4\n",
      "\n",
      "trees: 60, max-depth: 6\n",
      "\n",
      "trees: 60, max-depth: 8\n",
      "New max score: 0.5426878288058165\n",
      "\n",
      "trees: 70, max-depth: 2\n",
      "\n",
      "trees: 70, max-depth: 4\n",
      "\n",
      "trees: 70, max-depth: 6\n",
      "\n",
      "trees: 70, max-depth: 8\n",
      "\n",
      "trees: 80, max-depth: 2\n",
      "\n",
      "trees: 80, max-depth: 4\n",
      "\n",
      "trees: 80, max-depth: 6\n",
      "\n",
      "trees: 80, max-depth: 8\n",
      "\n",
      "trees: 90, max-depth: 2\n",
      "\n",
      "trees: 90, max-depth: 4\n",
      "\n",
      "trees: 90, max-depth: 6\n",
      "\n",
      "trees: 90, max-depth: 8\n",
      "New max score: 0.5434844159647483\n",
      "\n",
      "trees: 100, max-depth: 2\n",
      "\n",
      "trees: 100, max-depth: 4\n",
      "\n",
      "trees: 100, max-depth: 6\n",
      "\n",
      "trees: 100, max-depth: 8\n",
      "New max score: 0.5440218843540023\n",
      "\n",
      "trees: 110, max-depth: 2\n",
      "\n",
      "trees: 110, max-depth: 4\n",
      "\n",
      "trees: 110, max-depth: 6\n",
      "\n",
      "trees: 110, max-depth: 8\n",
      "New max score: 0.5464495608611459\n",
      "\n",
      "trees: 120, max-depth: 2\n",
      "\n",
      "trees: 120, max-depth: 4\n",
      "\n",
      "trees: 120, max-depth: 6\n",
      "\n",
      "trees: 120, max-depth: 8\n",
      "\n",
      "trees: 130, max-depth: 2\n",
      "\n",
      "trees: 130, max-depth: 4\n",
      "\n",
      "trees: 130, max-depth: 6\n",
      "\n",
      "trees: 130, max-depth: 8\n",
      "\n",
      "trees: 140, max-depth: 2\n",
      "\n",
      "trees: 140, max-depth: 4\n",
      "\n",
      "trees: 140, max-depth: 6\n",
      "\n",
      "trees: 140, max-depth: 8\n",
      "\n",
      "trees: 150, max-depth: 2\n",
      "\n",
      "trees: 150, max-depth: 4\n",
      "\n",
      "trees: 150, max-depth: 6\n",
      "\n",
      "trees: 150, max-depth: 8\n",
      "\n",
      "trees: 160, max-depth: 2\n",
      "\n",
      "trees: 160, max-depth: 4\n",
      "\n",
      "trees: 160, max-depth: 6\n",
      "\n",
      "trees: 160, max-depth: 8\n",
      "\n",
      "trees: 170, max-depth: 2\n",
      "\n",
      "trees: 170, max-depth: 4\n",
      "\n",
      "trees: 170, max-depth: 6\n",
      "\n",
      "trees: 170, max-depth: 8\n",
      "\n",
      "trees: 180, max-depth: 2\n",
      "\n",
      "trees: 180, max-depth: 4\n",
      "\n",
      "trees: 180, max-depth: 6\n",
      "\n",
      "trees: 180, max-depth: 8\n",
      "\n",
      "trees: 190, max-depth: 2\n",
      "\n",
      "trees: 190, max-depth: 4\n",
      "\n",
      "trees: 190, max-depth: 6\n",
      "\n",
      "trees: 190, max-depth: 8\n",
      "\n",
      "\n",
      "best RANDOM FOREST\n",
      "train score: 0.6399714388451692\n",
      "test score: 0.5464495608611459\n",
      "num rows: 11525\n",
      "trees: 110\n",
      "max-depth: 8\n",
      "\n",
      "\n",
      "\n",
      "trees: 40, max-depth: 2\n",
      "New max score: 0.40981132902674566\n",
      "\n",
      "trees: 40, max-depth: 4\n",
      "New max score: 0.4943126489451428\n",
      "\n",
      "trees: 40, max-depth: 6\n",
      "New max score: 0.6004525709832437\n",
      "\n",
      "trees: 40, max-depth: 8\n",
      "New max score: 0.7186300259267705\n",
      "\n",
      "trees: 50, max-depth: 2\n",
      "\n",
      "trees: 50, max-depth: 4\n",
      "\n",
      "trees: 50, max-depth: 6\n",
      "\n",
      "trees: 50, max-depth: 8\n",
      "New max score: 0.7476937666810343\n",
      "\n",
      "trees: 60, max-depth: 2\n",
      "\n",
      "trees: 60, max-depth: 4\n",
      "\n",
      "trees: 60, max-depth: 6\n",
      "\n",
      "trees: 60, max-depth: 8\n",
      "New max score: 0.7687034297612021\n",
      "\n",
      "trees: 70, max-depth: 2\n",
      "\n",
      "trees: 70, max-depth: 4\n",
      "\n",
      "trees: 70, max-depth: 6\n",
      "\n",
      "trees: 70, max-depth: 8\n",
      "New max score: 0.783721064008338\n",
      "\n",
      "trees: 80, max-depth: 2\n",
      "\n",
      "trees: 80, max-depth: 4\n",
      "\n",
      "trees: 80, max-depth: 6\n",
      "\n",
      "trees: 80, max-depth: 8\n",
      "New max score: 0.7955251038891644\n",
      "\n",
      "trees: 90, max-depth: 2\n",
      "\n",
      "trees: 90, max-depth: 4\n",
      "\n",
      "trees: 90, max-depth: 6\n",
      "\n",
      "trees: 90, max-depth: 8\n",
      "New max score: 0.8069555505776288\n",
      "\n",
      "trees: 100, max-depth: 2\n",
      "\n",
      "trees: 100, max-depth: 4\n",
      "\n",
      "trees: 100, max-depth: 6\n",
      "\n",
      "trees: 100, max-depth: 8\n",
      "New max score: 0.8143481626392972\n",
      "\n",
      "trees: 110, max-depth: 2\n",
      "\n",
      "trees: 110, max-depth: 4\n",
      "\n",
      "trees: 110, max-depth: 6\n",
      "\n",
      "trees: 110, max-depth: 8\n",
      "New max score: 0.8197607352204302\n",
      "\n",
      "trees: 120, max-depth: 2\n",
      "\n",
      "trees: 120, max-depth: 4\n",
      "\n",
      "trees: 120, max-depth: 6\n",
      "\n",
      "trees: 120, max-depth: 8\n",
      "New max score: 0.8267601432199913\n",
      "\n",
      "trees: 130, max-depth: 2\n",
      "\n",
      "trees: 130, max-depth: 4\n",
      "\n",
      "trees: 130, max-depth: 6\n",
      "\n",
      "trees: 130, max-depth: 8\n",
      "New max score: 0.8304386617249016\n",
      "\n",
      "trees: 140, max-depth: 2\n",
      "\n",
      "trees: 140, max-depth: 4\n",
      "\n",
      "trees: 140, max-depth: 6\n",
      "\n",
      "trees: 140, max-depth: 8\n",
      "New max score: 0.838724036100308\n",
      "\n",
      "trees: 150, max-depth: 2\n",
      "\n",
      "trees: 150, max-depth: 4\n",
      "\n",
      "trees: 150, max-depth: 6\n",
      "\n",
      "trees: 150, max-depth: 8\n",
      "New max score: 0.8397683202024544\n",
      "\n",
      "trees: 160, max-depth: 2\n",
      "\n",
      "trees: 160, max-depth: 4\n",
      "\n",
      "trees: 160, max-depth: 6\n",
      "\n",
      "trees: 160, max-depth: 8\n",
      "New max score: 0.8436811023347963\n",
      "\n",
      "trees: 170, max-depth: 2\n",
      "\n",
      "trees: 170, max-depth: 4\n",
      "\n",
      "trees: 170, max-depth: 6\n",
      "\n",
      "trees: 170, max-depth: 8\n",
      "New max score: 0.8494205673662549\n",
      "\n",
      "trees: 180, max-depth: 2\n",
      "\n",
      "trees: 180, max-depth: 4\n",
      "\n",
      "trees: 180, max-depth: 6\n",
      "\n",
      "trees: 180, max-depth: 8\n",
      "New max score: 0.8529232210582913\n",
      "\n",
      "trees: 190, max-depth: 2\n",
      "\n",
      "trees: 190, max-depth: 4\n",
      "\n",
      "trees: 190, max-depth: 6\n",
      "\n",
      "trees: 190, max-depth: 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m results_rf \u001b[38;5;241m=\u001b[39m run(RandomForestRegressor, X, y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANDOM FOREST\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m results_gb \u001b[38;5;241m=\u001b[39m run(GradientBoostingRegressor, X, y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRADIENT BOOSTING\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 22\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, X, y, model_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m X_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     20\u001b[0m forest_data \u001b[38;5;241m=\u001b[39m [X_train, X_test, y_train, y_test] \n\u001b[1;32m---> 22\u001b[0m scores \u001b[38;5;241m=\u001b[39m test_model(model(n_estimators\u001b[38;5;241m=\u001b[39mtrees, max_depth\u001b[38;5;241m=\u001b[39mdepth), forest_data)\n\u001b[0;32m     24\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((trees, depth, scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m>\u001b[39mmax_r2:\n",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_model\u001b[39m(model, data):\n\u001b[0;32m      3\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m----> 4\u001b[0m     reg \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m     train_score \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mscore(X_train, y_train)\n\u001b[0;32m      7\u001b[0m     test_score \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\deers\\anaconda3\\envs\\dev\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\deers\\anaconda3\\envs\\dev\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\deers\\anaconda3\\envs\\dev\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X, residual, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\deers\\anaconda3\\envs\\dev\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\deers\\anaconda3\\envs\\dev\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_rf = run(RandomForestRegressor, X, y, 'RANDOM FOREST')\n",
    "results_gb = run(GradientBoostingRegressor, X, y, 'GRADIENT BOOSTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard regressors\n",
    "# test_model(LinearRegression(), data)\n",
    "\n",
    "# test_model(KNeighborsRegressor(), data)\n",
    "# test_model(RandomForestRegressor(), data)\n",
    "# test_model(ExtraTreesRegressor(), data)\n",
    "# test_model(AdaBoostRegressor(), data)\n",
    "# test_model(SVR(C=1.0, epsilon=0.2), data)\n",
    "# test_model(GradientBoostingRegressor(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models\n",
    "# models = [\n",
    "#     LinearRegression(),\n",
    "#     KNeighborsRegressor(),\n",
    "#     RandomForestRegressor(),\n",
    "#     ExtraTreesRegressor(),\n",
    "#     AdaBoostRegressor(),\n",
    "#     SVR(C=1.0, epsilon=0.2),\n",
    "#     GradientBoostingRegressor()\n",
    "# ]\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a tuple of the training and test sets\n",
    "# data_split = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# # Iterate through the models and print the scores for each one\n",
    "# for model in models:\n",
    "#     scores = test_model(model, data_split)\n",
    "#     print(f'Model: {type(model).__name__}, Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
